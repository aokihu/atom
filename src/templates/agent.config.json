{
  "agent": {
    "name": "MyAgent",
    "model": "deepseek/deepseek-chat",
    "params": {
      "temperature": 0.2,
      "maxOutputTokens": 4096
    },
    "execution": {
      "maxModelStepsPerRun": 10,
      "autoContinueOnStepLimit": true,
      "maxToolCallsPerTask": 40,
      "maxContinuationRuns": 5,
      "maxModelStepsPerTask": 80,
      "continueWithoutAdvancingContextRound": true,
      "contextV2": {
        "enabled": true,
        "apiDualMode": true,
        "injectLiteOnly": true
      },
      "inputPolicy": {
        "enabled": true,
        "autoCompress": true,
        "maxInputTokens": 12000,
        "summarizeTargetTokens": 1800
      },
      "contextBudget": {
        "enabled": true,
        "contextWindowTokens": 131072,
        "reserveOutputTokensMax": 2048,
        "safetyMarginRatio": 0.12,
        "safetyMarginMinTokens": 6000,
        "outputStepDownTokens": [2048, 1024, 512]
      },
      "overflowPolicy": {
        "isolateTaskOnContextOverflow": true
      },
      "intentGuard": {
        "enabled": true,
        "detector": {
          "mode": "hybrid",
          "timeoutMs": 600,
          "modelMaxOutputTokens": 80
        }
      }
    }
  },
  "providers": [
    {
      "provider_id": "deepseek",
      "model": "deepseek-chat",
      "api_key": "YOUR_DEEPSEEK_API_KEY",
      "max_context_tokens": 131072,
      "max_output_tokens": 8192,
      "enabled": true
    },
    {
      "provider_id": "openrouter",
      "model": "openai/gpt-4o-mini",
      "api_key": "YOUR_OPENROUTER_API_KEY",
      "enabled": false
    },
    {
      "provider_id": "openai",
      "model": "gpt-4o-mini",
      "api_key": "YOUR_OPENAI_API_KEY",
      "enabled": false
    },
    {
      "provider_id": "siliconflow",
      "model": "deepseek-ai/DeepSeek-V3",
      "api_key": "YOUR_SILICONFLOW_API_KEY",
      "enabled": false
    },
    {
      "provider_id": "dashscope",
      "model": "qwen-plus",
      "api_key": "YOUR_DASHSCOPE_API_KEY",
      "enabled": false
    },
    {
      "provider_id": "ollama",
      "model": "qwen2.5:7b",
      "api_key": "OLLAMA_DUMMY_KEY",
      "enabled": false
    }
  ],
  "permissions": {
    "read": {
      "allow": ["^{workspace}/.*"],
      "deny": []
    },
    "ls": {
      "allow": ["^{workspace}/.*"],
      "deny": []
    },
    "tree": {
      "allow": ["^{workspace}/.*"],
      "deny": []
    },
    "ripgrep": {
      "allow": ["^{workspace}/.*"],
      "deny": []
    },
    "write": {
      "allow": ["^{workspace}/.*"],
      "deny": []
    },
    "cp": {
      "allow": ["^{workspace}/.*"],
      "deny": []
    },
    "mv": {
      "allow": ["^{workspace}/.*"],
      "deny": []
    },
    "git": {
      "allow": ["^{workspace}/.*"],
      "deny": []
    },
    "bash": {
      "allow": ["^{workspace}/.*"],
      "deny": []
    },
    "background": {
      "allow": ["^{workspace}/.*"],
      "deny": []
    },
    "webfetch": {
      "allow": ["^https://(docs\\.|developer\\.)?example\\.com/.*"],
      "deny": ["^https?://(localhost|127\\.0\\.0\\.1)(:.*)?/.*"]
    }
  },
  "memory": {
    "persistent": {
      "enabled": true,
      "storagePath": "{workspace}/.agent/persistent-memory.jsonl",
      "walPath": "{workspace}/.agent/memory-queue.wal",
      "recallLimit": 24,
      "maxEntries": 4000,
      "pipeline": {
        "mode": "async_wal",
        "recallTimeoutMs": 40,
        "batchSize": 32,
        "flushIntervalMs": 200,
        "flushOnShutdownTimeoutMs": 3000
      }
    }
  }
}
